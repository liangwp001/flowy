# ğŸŒŠ Flowy

<div align="center">

**ä¸€ä¸ªç°ä»£åŒ–çš„ Python å·¥ä½œæµç®¡ç†æ¡†æ¶ï¼Œå¸¦æœ‰å¼ºå¤§çš„ Web ç®¡ç†ç•Œé¢**

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Framework](https://img.shields.io/badge/framework-Flask-red.svg)](https://flask.palletsprojects.com/)

[åŠŸèƒ½ç‰¹æ€§](#-åŠŸèƒ½ç‰¹æ€§) â€¢ [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [å®‰è£…æ–¹æ³•](#-å®‰è£…æ–¹æ³•) â€¢ [ä½¿ç”¨åœºæ™¯](#-ä½¿ç”¨åœºæ™¯) â€¢ [Webç•Œé¢](#-webç•Œé¢) â€¢ [APIæ–‡æ¡£](#-apiæ–‡æ¡£)

</div>

---

## ğŸš€ æ ¸å¿ƒä»·å€¼

Flowy æ˜¯ä¸€ä¸ªä¸“ä¸º Python å¼€å‘è€…è®¾è®¡çš„è½»é‡çº§å·¥ä½œæµç®¡ç†æ¡†æ¶ï¼Œè®©å¤æ‚çš„ä¸šåŠ¡æµç¨‹å˜å¾—ç®€å•æ˜“ç®¡ç†ï¼š

- **ğŸ¯ ç®€å•æ˜“ç”¨** - ä»…éœ€å‡ è¡Œä»£ç å³å¯å®šä¹‰å¤æ‚å·¥ä½œæµ
- **ğŸ“Š å¯è§†åŒ–ç®¡ç†** - ç°ä»£åŒ– Web ç•Œé¢ï¼Œå®æ—¶ç›‘æ§æ‰§è¡ŒçŠ¶æ€
- **â° å®šæ—¶è°ƒåº¦** - æ”¯æŒ Cron è¡¨è¾¾å¼çš„çµæ´»ä»»åŠ¡è°ƒåº¦
- **ğŸ“ å®Œæ•´æ—¥å¿—** - è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—å’Œé”™è¯¯è¿½è¸ª
- **ğŸ”„ è‡ªåŠ¨é‡è¯•** - å†…ç½®é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- **ğŸ“ˆ ç»Ÿè®¡åˆ†æ** - ä¸°å¯Œçš„æ‰§è¡Œç»Ÿè®¡å’Œæ€§èƒ½åˆ†æ

## âœ¨ åŠŸèƒ½ç‰¹æ€§

### ğŸ¨ è£…é¥°å™¨é©±åŠ¨
ä½¿ç”¨ç®€æ´çš„è£…é¥°å™¨è¯­æ³•å®šä¹‰ä»»åŠ¡å’Œå·¥ä½œæµï¼Œä»£ç æ¸…æ™°æ˜“è¯»

### ğŸ–¥ï¸ Web ç®¡ç†ç•Œé¢
- å·¥ä½œæµåˆ—è¡¨å’Œè¯¦æƒ…æŸ¥çœ‹
- å®æ—¶æ‰§è¡ŒçŠ¶æ€ç›‘æ§
- æ‰§è¡Œå†å²å’Œæ—¥å¿—æŸ¥çœ‹
- å®šæ—¶è§¦å‘å™¨ç®¡ç†
- ç»Ÿè®¡å›¾è¡¨å’Œæ€§èƒ½åˆ†æ

### âš¡ é«˜æ€§èƒ½è°ƒåº¦
- åŸºäº APScheduler çš„å¼ºå¤§è°ƒåº¦å¼•æ“
- æ”¯æŒ Cron è¡¨è¾¾å¼å®šæ—¶æ‰§è¡Œ
- å¹¶å‘æ‰§è¡Œæ§åˆ¶
- ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†

### ğŸ“Š æ•°æ®æŒä¹…åŒ–
- SQLite æ•°æ®åº“å­˜å‚¨
- å®Œæ•´çš„æ‰§è¡Œå†å²è®°å½•
- ç»“æ„åŒ–æ—¥å¿—ç®¡ç†
- æ•°æ®å¯¼å‡ºåŠŸèƒ½

## ğŸ› ï¸ å®‰è£…æ–¹æ³•

### ä» GitHub å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# ç›´æ¥ä» GitHub å®‰è£…æœ€æ–°ç‰ˆæœ¬
pip install git+https://github.com/liangwp001/flowy.git

# æˆ–è€…å®‰è£…ç‰¹å®šç‰ˆæœ¬
pip install git+https://github.com/liangwp001/flowy.git@v0.1.0
```

### ä»æºç å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/liangwp001/flowy.git
cd flowy

# å®‰è£…ä¾èµ–å¹¶å®‰è£…
pip install -e .
```

### ä¾èµ–è¦æ±‚

- Python 3.10+
- Flask 3.0+
- SQLAlchemy 2.0+
- APScheduler 3.10+

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ªå·¥ä½œæµ

```python
from flowy import flow, task, run, get_flow_logger

# å®šä¹‰ä»»åŠ¡
@task(name="æ•°æ®éªŒè¯", desc="éªŒè¯è¾“å…¥æ•°æ®çš„æœ‰æ•ˆæ€§")
def validate_data(data: dict) -> dict:
    logger = get_flow_logger()
    logger.info(f"å¼€å§‹éªŒè¯æ•°æ®: {data}")
    
    if not data.get('name') or not data.get('age'):
        raise ValueError("ç¼ºå°‘å¿…è¦å­—æ®µ")
    
    logger.info("æ•°æ®éªŒè¯é€šè¿‡")
    return data

@task(name="æ•°æ®å¤„ç†", desc="å¤„ç†å’Œè½¬æ¢æ•°æ®")
def process_data(data: dict) -> dict:
    logger = get_flow_logger()
    logger.info("å¼€å§‹å¤„ç†æ•°æ®")
    
    result = {
        'name': data['name'].upper(),
        'age': data['age'],
        'is_adult': data['age'] >= 18
    }
    
    logger.info(f"æ•°æ®å¤„ç†å®Œæˆ: {result}")
    return result

# å®šä¹‰å·¥ä½œæµ
@flow(flow_id="user_data_flow", name="ç”¨æˆ·æ•°æ®å¤„ç†æµç¨‹", desc="éªŒè¯å’Œå¤„ç†ç”¨æˆ·æ•°æ®")
def user_data_flow(name: str, age: int) -> dict:
    # æ­¥éª¤1: éªŒè¯æ•°æ®
    input_data = {'name': name, 'age': age}
    validated_data = validate_data(input_data)
    
    # æ­¥éª¤2: å¤„ç†æ•°æ®
    processed_data = process_data(validated_data)
    
    return processed_data

if __name__ == '__main__':
    # æ‰§è¡Œå·¥ä½œæµ
    # result = user_data_flow(name="å¼ ä¸‰", age=25)
    # print(f"å¤„ç†ç»“æœ: {result}")
    
    # å¯åŠ¨ Web ç®¡ç†ç•Œé¢
    run(host='127.0.0.1', port=5000, debug=True)
```

### 2. å¯åŠ¨ Web ç•Œé¢

è¿è¡Œä¸Šè¿°ä»£ç åï¼Œè®¿é—® `http://127.0.0.1:5000` å³å¯çœ‹åˆ° Flowy çš„ç®¡ç†ç•Œé¢ã€‚

### 3. æ·»åŠ å®šæ—¶è°ƒåº¦

é€šè¿‡ Web ç•Œé¢æˆ– API ä¸ºå·¥ä½œæµæ·»åŠ å®šæ—¶è§¦å‘å™¨ï¼š

```python
# é€šè¿‡ API æ·»åŠ æ¯æ—¥æ‰§è¡Œçš„è§¦å‘å™¨
import requests

trigger_data = {
    "name": "æ¯æ—¥æ•°æ®å¤„ç†",
    "description": "æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œç”¨æˆ·æ•°æ®å¤„ç†",
    "cron_expression": "0 2 * * *",  # æ¯å¤©å‡Œæ™¨2ç‚¹
    "trigger_params": {
        "name": "ç³»ç»Ÿç”¨æˆ·",
        "age": 30
    }
}

response = requests.post(
    "http://127.0.0.1:5000/api/triggers",
    json=trigger_data
)
```

### 4. ç›‘æ§å’Œç®¡ç†

åœ¨ Web ç•Œé¢ä¸­ä½ å¯ä»¥ï¼š
- ğŸ“Š æŸ¥çœ‹å·¥ä½œæµæ‰§è¡Œç»Ÿè®¡å’Œè¶‹åŠ¿å›¾è¡¨
- ğŸ“ å®æ—¶æŸ¥çœ‹æ‰§è¡Œæ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯
- â° ç®¡ç†å®šæ—¶è§¦å‘å™¨çš„å¯ç”¨/ç¦ç”¨çŠ¶æ€
- ğŸ”„ æ‰‹åŠ¨è§¦å‘å·¥ä½œæµæ‰§è¡Œå¹¶ä¼ å…¥å‚æ•°
- ğŸ“ˆ åˆ†æå·¥ä½œæµæ€§èƒ½å’Œèµ„æºä½¿ç”¨æƒ…å†µ

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### ğŸ“Š æ•°æ®å¤„ç†ç®¡é“
æ„å»ºå¼ºå¤§çš„ ETL æ•°æ®å¤„ç†æµæ°´çº¿ï¼š

```python
from flowy import flow, task, get_flow_logger
import pandas as pd

@task(name="æ•°æ®æå–", desc="ä»å¤šä¸ªæ•°æ®æºæå–æ•°æ®")
def extract_data(sources: list) -> dict:
    logger = get_flow_logger()
    extracted_data = {}
    
    for source in sources:
        logger.info(f"æ­£åœ¨æå–æ•°æ®æº: {source['name']}")
        # æ¨¡æ‹Ÿæ•°æ®æå–
        data = pd.read_csv(source['path'])
        extracted_data[source['name']] = data
        logger.info(f"æå–å®Œæˆï¼Œè®°å½•æ•°: {len(data)}")
    
    return extracted_data

@task(name="æ•°æ®æ¸…æ´—", desc="æ¸…æ´—å’ŒéªŒè¯æ•°æ®è´¨é‡")
def clean_data(raw_data: dict) -> dict:
    logger = get_flow_logger()
    cleaned_data = {}
    
    for source_name, data in raw_data.items():
        logger.info(f"æ­£åœ¨æ¸…æ´—æ•°æ®æº: {source_name}")
        # æ•°æ®æ¸…æ´—é€»è¾‘
        cleaned = data.dropna().drop_duplicates()
        cleaned_data[source_name] = cleaned
        logger.info(f"æ¸…æ´—å®Œæˆï¼Œæœ‰æ•ˆè®°å½•: {len(cleaned)}")
    
    return cleaned_data

@task(name="æ•°æ®åŠ è½½", desc="å°†å¤„ç†åçš„æ•°æ®åŠ è½½åˆ°ç›®æ ‡ç³»ç»Ÿ")
def load_data(processed_data: dict, target_db: str) -> dict:
    logger = get_flow_logger()
    results = {}
    
    for source_name, data in processed_data.items():
        logger.info(f"æ­£åœ¨åŠ è½½æ•°æ®: {source_name} -> {target_db}")
        # æ¨¡æ‹Ÿæ•°æ®åŠ è½½
        # data.to_sql(source_name, target_db, if_exists='replace')
        results[source_name] = len(data)
        logger.info(f"åŠ è½½å®Œæˆï¼Œè®°å½•æ•°: {len(data)}")
    
    return results

@flow(flow_id="etl_pipeline", name="ETLæ•°æ®ç®¡é“", desc="å®Œæ•´çš„æ•°æ®æå–ã€è½¬æ¢ã€åŠ è½½æµç¨‹")
def etl_pipeline(config: dict) -> dict:
    """ETLæ•°æ®å¤„ç†ç®¡é“
    
    Args:
        config: åŒ…å«æ•°æ®æºå’Œç›®æ ‡é…ç½®çš„å­—å…¸
    
    Returns:
        å¤„ç†ç»“æœç»Ÿè®¡
    """
    logger = get_flow_logger()
    logger.info("å¼€å§‹æ‰§è¡ŒETLæ•°æ®ç®¡é“")
    
    # æ­¥éª¤1: æå–æ•°æ®
    raw_data = extract_data(config['sources'])
    
    # æ­¥éª¤2: æ¸…æ´—æ•°æ®
    cleaned_data = clean_data(raw_data)
    
    # æ­¥éª¤3: åŠ è½½æ•°æ®
    load_results = load_data(cleaned_data, config['target_db'])
    
    # ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
    total_records = sum(load_results.values())
    logger.info(f"ETLç®¡é“æ‰§è¡Œå®Œæˆï¼Œæ€»å¤„ç†è®°å½•æ•°: {total_records}")
    
    return {
        "total_records": total_records,
        "sources_processed": len(load_results),
        "details": load_results
    }
```

### ğŸ”„ å®šæ—¶æŠ¥è¡¨ç”Ÿæˆ
è‡ªåŠ¨åŒ–çš„æŠ¥è¡¨ç”Ÿæˆå’Œåˆ†å‘ç³»ç»Ÿï¼š

```python
@task(name="æ•°æ®æ”¶é›†", desc="æ”¶é›†å„ç³»ç»Ÿçš„ä¸šåŠ¡æŒ‡æ ‡")
def collect_metrics(date_range: dict) -> dict:
    logger = get_flow_logger()
    logger.info(f"æ”¶é›† {date_range['start']} åˆ° {date_range['end']} çš„æ•°æ®")
    
    # æ¨¡æ‹Ÿä»å„ä¸ªç³»ç»Ÿæ”¶é›†æ•°æ®
    metrics = {
        'sales': {'revenue': 150000, 'orders': 1200},
        'users': {'new_users': 450, 'active_users': 8900},
        'system': {'uptime': 99.9, 'response_time': 120}
    }
    
    return metrics

@task(name="æŠ¥è¡¨ç”Ÿæˆ", desc="ç”Ÿæˆå¤šæ ¼å¼ä¸šåŠ¡æŠ¥è¡¨")
def generate_report(metrics: dict, template: str) -> dict:
    logger = get_flow_logger()
    logger.info(f"ä½¿ç”¨æ¨¡æ¿ {template} ç”ŸæˆæŠ¥è¡¨")
    
    # ç”ŸæˆæŠ¥è¡¨æ–‡ä»¶
    report_data = {
        'file_path': f'/reports/daily_report_{datetime.now().strftime("%Y%m%d")}.pdf',
        'summary': metrics,
        'charts': ['revenue_trend', 'user_growth', 'system_health']
    }
    
    logger.info("æŠ¥è¡¨ç”Ÿæˆå®Œæˆ")
    return report_data

@task(name="æŠ¥è¡¨åˆ†å‘", desc="å°†æŠ¥è¡¨å‘é€ç»™ç›¸å…³äººå‘˜")
def distribute_report(report: dict, recipients: list) -> dict:
    logger = get_flow_logger()
    
    sent_count = 0
    for recipient in recipients:
        logger.info(f"å‘é€æŠ¥è¡¨ç»™: {recipient['email']}")
        # æ¨¡æ‹Ÿé‚®ä»¶å‘é€
        sent_count += 1
    
    return {"sent_count": sent_count, "report_path": report['file_path']}

@flow(flow_id="daily_report", name="æ¯æ—¥ä¸šåŠ¡æŠ¥è¡¨", desc="è‡ªåŠ¨ç”Ÿæˆå’Œåˆ†å‘æ¯æ—¥ä¸šåŠ¡æŠ¥è¡¨")
def daily_report_flow(report_date: str = None) -> dict:
    from datetime import datetime, timedelta
    
    if not report_date:
        report_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    # æ”¶é›†æŒ‡æ ‡æ•°æ®
    date_range = {'start': report_date, 'end': report_date}
    metrics = collect_metrics(date_range)
    
    # ç”ŸæˆæŠ¥è¡¨
    report = generate_report(metrics, 'daily_business_template')
    
    # åˆ†å‘æŠ¥è¡¨
    recipients = [
        {'email': 'ceo@company.com', 'name': 'CEO'},
        {'email': 'cto@company.com', 'name': 'CTO'},
        {'email': 'sales@company.com', 'name': 'Sales Team'}
    ]
    distribution_result = distribute_report(report, recipients)
    
    return {
        'report_date': report_date,
        'metrics_summary': metrics,
        'distribution': distribution_result
    }
```


## ğŸ–¥ï¸ Webç•Œé¢

Flowy æä¾›äº†ç°ä»£åŒ–ã€ç›´è§‚çš„ Web ç®¡ç†ç•Œé¢ï¼Œè®©å·¥ä½œæµç®¡ç†å˜å¾—è½»æ¾æ„‰å¿«ã€‚

### ğŸ“‹ å·¥ä½œæµç®¡ç†
![å·¥ä½œæµåˆ—è¡¨](pics/flow-list.png)

- **æµç¨‹åˆ—è¡¨**: æŸ¥çœ‹æ‰€æœ‰å·²å®šä¹‰çš„å·¥ä½œæµï¼Œæ”¯æŒæœç´¢å’Œç­›é€‰
- **æ‰§è¡Œç»Ÿè®¡**: æˆåŠŸç‡ã€å¹³å‡æ‰§è¡Œæ—¶é—´ç­‰å…³é”®æŒ‡æ ‡
- **å®æ—¶ç›‘æ§**: å½“å‰è¿è¡ŒçŠ¶æ€å’Œè¿›åº¦è·Ÿè¸ª
- **ä¸€é”®æ‰§è¡Œ**: ç›´æ¥åœ¨ç•Œé¢ä¸­è§¦å‘å·¥ä½œæµæ‰§è¡Œ

### ğŸ“Š æ‰§è¡Œå†å²
![æ‰§è¡Œå†å²](pics/execution-history.png)

- **è¯¦ç»†æ—¥å¿—**: æ¯ä¸ªä»»åŠ¡çš„æ‰§è¡Œæ—¥å¿—å’Œè¾“å‡º
- **é”™è¯¯è¿½è¸ª**: å®Œæ•´çš„é”™è¯¯å †æ ˆå’Œè°ƒè¯•ä¿¡æ¯
- **æ€§èƒ½åˆ†æ**: æ‰§è¡Œæ—¶é—´åˆ†æå’Œç“¶é¢ˆè¯†åˆ«
- **æ•°æ®å¯è§†åŒ–**: å›¾è¡¨å±•ç¤ºæ‰§è¡Œè¶‹åŠ¿

### ğŸ“ˆ Flow è¯¦æƒ…ä¸ç»Ÿè®¡
![Flowè¯¦æƒ…](pics/flow-detail.png)

- **æ‰§è¡Œç»Ÿè®¡**: æˆåŠŸç‡ã€å¹³å‡æ‰§è¡Œæ—¶é—´ç­‰å…³é”®æŒ‡æ ‡
- **æ€§èƒ½å›¾è¡¨**: æ‰§è¡Œè¶‹åŠ¿ã€æ—¶é•¿åˆ†å¸ƒã€24å°æ—¶åˆ†æ
- **è§¦å‘å™¨ç®¡ç†**: å®šæ—¶ä»»åŠ¡çš„åˆ›å»ºå’Œç®¡ç†
- **å®æ—¶ç›‘æ§**: å½“å‰è¿è¡ŒçŠ¶æ€å’Œå†å²è®°å½•

### â° å®šæ—¶è§¦å‘å™¨
![å®šæ—¶è§¦å‘å™¨](pics/triggers-management.png)

- **Cron è§¦å‘å™¨**: çµæ´»çš„å®šæ—¶æ‰§è¡Œé…ç½®
- **è§¦å‘å™¨ç®¡ç†**: å¯ç”¨/ç¦ç”¨ã€ç¼–è¾‘è°ƒåº¦è§„åˆ™
- **æ‰§è¡Œè®¡åˆ’**: æŸ¥çœ‹å³å°†æ‰§è¡Œçš„ä»»åŠ¡
- **å‚æ•°é…ç½®**: ä¸ºå®šæ—¶ä»»åŠ¡é…ç½®æ‰§è¡Œå‚æ•°

### ğŸ” æ‰§è¡Œè¯¦æƒ…
![æ‰§è¡Œè¯¦æƒ…](pics/execution-detail.png)

- **è¯¦ç»†ä¿¡æ¯**: å®Œæ•´çš„æ‰§è¡Œè¿‡ç¨‹å’Œç»“æœ
- **è¾“å…¥è¾“å‡º**: JSON æ ¼å¼çš„æ•°æ®å±•ç¤º
- **ä»»åŠ¡è¿½è¸ª**: æ¯ä¸ªå­ä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€
- **é”™è¯¯è¯Šæ–­**: å®Œæ•´çš„é”™è¯¯å †æ ˆå’Œè°ƒè¯•ä¿¡æ¯

## ğŸ“š APIæ–‡æ¡£

### è£…é¥°å™¨

#### `@task(name=None, desc=None)`
å®šä¹‰ä¸€ä¸ªå¯é‡ç”¨çš„ä»»åŠ¡å•å…ƒ

**å‚æ•°:**
- `name` (str, å¯é€‰): ä»»åŠ¡æ˜¾ç¤ºåç§°
- `desc` (str, å¯é€‰): ä»»åŠ¡æè¿°

#### `@flow(flow_id, name=None, desc=None)`
å®šä¹‰ä¸€ä¸ªå·¥ä½œæµ

**å‚æ•°:**
- `flow_id` (str, å¿…éœ€): å·¥ä½œæµå”¯ä¸€æ ‡è¯†ç¬¦
- `name` (str, å¯é€‰): å·¥ä½œæµæ˜¾ç¤ºåç§°
- `desc` (str, å¯é€‰): å·¥ä½œæµæè¿°

### æ ¸å¿ƒå‡½æ•°

#### `run(host='127.0.0.1', port=5000, debug=False)`
å¯åŠ¨ Web ç®¡ç†ç•Œé¢

**å‚æ•°:**
- `host` (str): æœåŠ¡å™¨åœ°å€
- `port` (int): ç«¯å£å·
- `debug` (bool): è°ƒè¯•æ¨¡å¼

#### `get_flow_logger()`
è·å–å½“å‰å·¥ä½œæµçš„æ—¥å¿—è®°å½•å™¨

**è¿”å›:** `logging.Logger` å¯¹è±¡

#### `configure(data_dir=None)`
é…ç½® Flowy æ•°æ®ç›®å½•

**å‚æ•°:**
- `data_dir` (str, å¯é€‰): æ•°æ®å­˜å‚¨ç›®å½•è·¯å¾„

### REST API

Flowy æä¾›å®Œæ•´çš„ REST API ç”¨äºé›†æˆå’Œè‡ªåŠ¨åŒ–ï¼š

```bash
# è·å–å·¥ä½œæµåˆ—è¡¨
GET /api/flows

# è§¦å‘å·¥ä½œæµæ‰§è¡Œ
POST /api/flows/{flow_id}/trigger

# è·å–æ‰§è¡Œå†å²
GET /api/flows/{flow_id}/history

# ç®¡ç†å®šæ—¶è§¦å‘å™¨
GET/POST/PUT/DELETE /api/triggers
```

## âš™ï¸ é«˜çº§åŠŸèƒ½

### ğŸ”„ é”™è¯¯å¤„ç†å’Œé‡è¯•
```python
@task(name="ç½‘ç»œè¯·æ±‚", desc="å¸¦é‡è¯•æœºåˆ¶çš„ç½‘ç»œè¯·æ±‚")
def fetch_data_with_retry(url: str, max_retries: int = 3) -> dict:
    logger = get_flow_logger()
    
    for attempt in range(max_retries):
        try:
            logger.info(f"å°è¯•è¯·æ±‚ {url} (ç¬¬ {attempt + 1} æ¬¡)")
            # æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.warning(f"è¯·æ±‚å¤±è´¥: {e}")
            if attempt == max_retries - 1:
                logger.error("è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¯·æ±‚å¤±è´¥")
                raise
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### ğŸ“Š æ¡ä»¶åˆ†æ”¯å’Œå¹¶è¡Œæ‰§è¡Œ
```python
@flow(flow_id="conditional_flow", name="æ¡ä»¶åˆ†æ”¯æµç¨‹")
def conditional_processing_flow(data_type: str, data: dict) -> dict:
    logger = get_flow_logger()
    
    # æ•°æ®éªŒè¯ï¼ˆæ€»æ˜¯æ‰§è¡Œï¼‰
    validated_data = validate_input(data)
    
    # æ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©ä¸åŒçš„å¤„ç†è·¯å¾„
    if data_type == "user_data":
        result = process_user_data(validated_data)
    elif data_type == "order_data":
        result = process_order_data(validated_data)
    elif data_type == "product_data":
        result = process_product_data(validated_data)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
    
    # æœ€ç»ˆå¤„ç†ï¼ˆæ€»æ˜¯æ‰§è¡Œï¼‰
    final_result = finalize_processing(result)
    return final_result
```

### ğŸ” å‚æ•°åŠ å¯†å’Œå®‰å…¨
```python
from flowy import flow, task, get_flow_logger
import os
from cryptography.fernet import Fernet

@task(name="å®‰å…¨æ•°æ®å¤„ç†", desc="å¤„ç†æ•æ„Ÿæ•°æ®")
def process_sensitive_data(encrypted_config: str) -> dict:
    logger = get_flow_logger()
    
    # ä»ç¯å¢ƒå˜é‡è·å–è§£å¯†å¯†é’¥
    key = os.environ.get('FLOWY_ENCRYPTION_KEY')
    if not key:
        raise ValueError("æœªæ‰¾åˆ°åŠ å¯†å¯†é’¥")
    
    # è§£å¯†é…ç½®
    fernet = Fernet(key.encode())
    config = json.loads(fernet.decrypt(encrypted_config.encode()))
    
    logger.info("å¼€å§‹å¤„ç†æ•æ„Ÿæ•°æ®ï¼ˆå·²è„±æ•æ—¥å¿—ï¼‰")
    # å¤„ç†æ•æ„Ÿæ•°æ®...
    
    return {"status": "success", "records_processed": 100}
```

## âš™ï¸ é…ç½®

### åŸºæœ¬é…ç½®
```python
from flowy import configure

# è‡ªå®šä¹‰æ•°æ®ç›®å½•
configure(data_dir='/path/to/your/data')
```

### ç¯å¢ƒå˜é‡
```bash
# æ•°æ®ç›®å½•
export FLOWY_DATA_DIR=/path/to/data

# æ—¥å¿—çº§åˆ«
export FLOWY_LOG_LEVEL=INFO

# Webç•Œé¢ç«¯å£
export FLOWY_WEB_PORT=5000

# æ•°æ®åº“è¿æ¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨SQLiteï¼‰
export FLOWY_DATABASE_URL=postgresql://user:pass@localhost/flowy

# åŠ å¯†å¯†é’¥ï¼ˆç”¨äºæ•æ„Ÿæ•°æ®ï¼‰
export FLOWY_ENCRYPTION_KEY=your-secret-key
```

### é…ç½®æ–‡ä»¶
åˆ›å»º `flowy.yaml` é…ç½®æ–‡ä»¶ï¼š

```yaml
# Flowy é…ç½®æ–‡ä»¶
database:
  url: "sqlite:///data/flowy.db"
  echo: false

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

web:
  host: "127.0.0.1"
  port: 5000
  debug: false

scheduler:
  max_workers: 10
  coalesce: true
  misfire_grace_time: 300

security:
  secret_key: "your-secret-key-here"
  session_timeout: 3600
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### ğŸ“ˆ æœ€ä½³å®è·µ

#### 1. ä»»åŠ¡è®¾è®¡åŸåˆ™
```python
# âœ… å¥½çš„åšæ³•ï¼šä»»åŠ¡èŒè´£å•ä¸€ï¼Œæ˜“äºæµ‹è¯•å’Œé‡ç”¨
@task(name="æ•°æ®éªŒè¯")
def validate_user_data(data: dict) -> dict:
    # åªè´Ÿè´£æ•°æ®éªŒè¯
    pass

@task(name="æ•°æ®è½¬æ¢")
def transform_user_data(data: dict) -> dict:
    # åªè´Ÿè´£æ•°æ®è½¬æ¢
    pass

# âŒ é¿å…ï¼šä¸€ä¸ªä»»åŠ¡åšå¤ªå¤šäº‹æƒ…
@task(name="å¤„ç†æ‰€æœ‰æ•°æ®")
def process_everything(data: dict) -> dict:
    # éªŒè¯ã€è½¬æ¢ã€ä¿å­˜éƒ½åœ¨ä¸€ä¸ªä»»åŠ¡ä¸­
    pass
```

#### 2. é”™è¯¯å¤„ç†ç­–ç•¥
```python
@task(name="å¥å£®çš„ä»»åŠ¡")
def robust_task(data: dict) -> dict:
    logger = get_flow_logger()
    
    try:
        # ä¸šåŠ¡é€»è¾‘
        result = process_data(data)
        return result
    except ValidationError as e:
        logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
        raise  # é‡æ–°æŠ›å‡ºï¼Œè®©å·¥ä½œæµå¤±è´¥
    except NetworkError as e:
        logger.warning(f"ç½‘ç»œé”™è¯¯ï¼Œç¨åé‡è¯•: {e}")
        time.sleep(5)
        return process_data(data)  # ç®€å•é‡è¯•
    except Exception as e:
        logger.error(f"æœªé¢„æœŸçš„é”™è¯¯: {e}")
        # è®°å½•è¯¦ç»†ä¿¡æ¯ç”¨äºè°ƒè¯•
        logger.error(traceback.format_exc())
        raise
```

#### 3. èµ„æºç®¡ç†
```python
@task(name="èµ„æºç®¡ç†ç¤ºä¾‹")
def resource_managed_task(file_path: str) -> dict:
    logger = get_flow_logger()
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾
    with open(file_path, 'r') as file:
        data = file.read()
    
    # å¯¹äºæ•°æ®åº“è¿æ¥
    with get_database_connection() as conn:
        result = conn.execute("SELECT * FROM users")
    
    return {"processed": True}
```

### ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

#### æ€§èƒ½ç›‘æ§
```python
import time
from functools import wraps

def monitor_performance(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        logger = get_flow_logger()
        start_time = time.time()
        
        try:
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.info(f"ä»»åŠ¡ {func.__name__} æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"ä»»åŠ¡ {func.__name__} æ‰§è¡Œå¤±è´¥ï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
            raise
    
    return wrapper

@task(name="æ€§èƒ½ç›‘æ§ä»»åŠ¡")
@monitor_performance
def monitored_task(data: dict) -> dict:
    # ä»»åŠ¡é€»è¾‘
    pass
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å·¥ä½œæµæ‰§è¡Œå¤±è´¥
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
tail -f data/log/flow-history-{history_id}.log

# æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
sqlite3 data/flowy.db ".tables"
```

#### 2. Webç•Œé¢æ— æ³•è®¿é—®
```python
# æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
netstat -an | grep :5000

# ä½¿ç”¨ä¸åŒç«¯å£å¯åŠ¨
run(host='127.0.0.1', port=8080)
```

#### 3. å®šæ—¶ä»»åŠ¡ä¸æ‰§è¡Œ
```python
# æ£€æŸ¥è§¦å‘å™¨çŠ¶æ€
from flowy.web.services.trigger_service import TriggerService
triggers = TriggerService.get_triggers_by_flow('your_flow_id')
for trigger in triggers:
    print(f"è§¦å‘å™¨ {trigger.name}: å¯ç”¨={trigger.enabled}")
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®
```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/liangwp001/flowy.git
cd flowy

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# 4. è¿è¡Œæµ‹è¯•
pytest tests/

# 5. ä»£ç æ ¼å¼åŒ–
black flowy/
isort flowy/
```

### è´¡çŒ®æµç¨‹
1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. ç¼–å†™ä»£ç å’Œæµ‹è¯•
4. ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡ (`pytest`)
5. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
6. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
7. å¼€å¯ Pull Request

### ä»£ç è§„èŒƒ
- éµå¾ª PEP 8 ä»£ç é£æ ¼
- ä¸ºæ–°åŠŸèƒ½æ·»åŠ æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°ç›¸å…³æ–‡æ¡£
- æäº¤ä¿¡æ¯ä½¿ç”¨è‹±æ–‡ï¼Œæ ¼å¼æ¸…æ™°

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

- [Flask](https://flask.palletsprojects.com/) - Web æ¡†æ¶
- [APScheduler](https://apscheduler.readthedocs.io/) - ä»»åŠ¡è°ƒåº¦
- [SQLAlchemy](https://www.sqlalchemy.org/) - æ•°æ®åº“ ORM
- [Chart.js](https://www.chartjs.org/) - å›¾è¡¨åº“

---

<div align="center">

**å¦‚æœ Flowy å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª â­ï¸**

[æŠ¥å‘Šé—®é¢˜](https://github.com/liangwp001/flowy/issues) â€¢ [åŠŸèƒ½è¯·æ±‚](https://github.com/liangwp001/flowy/issues) â€¢ [è®¨è®º](https://github.com/liangwp001/flowy/discussions)

</div>
